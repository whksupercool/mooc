{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(housing.data, housing.target, random_state=7)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_all, y_train_all, random_state=11)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"generate_csv\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "def save_to_csv(output_dir, data, name_prefix, header=None, n_parts=10):\n",
    "    path_format = os.path.join(output_dir, \"{}_{:02d}.csv\")\n",
    "    filenames = []\n",
    "    \n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(len(data)), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filenames.append(part_csv)\n",
    "        \n",
    "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "            if header is not None:\n",
    "                f.write(header + \"\\n\")\n",
    "            for row_index in row_indices:\n",
    "                f.write(\",\".join([repr(col) for col in data[row_index]]))\n",
    "                f.write(\"\\n\")\n",
    "            \n",
    "    return filenames\n",
    "\n",
    "train_data = np.c_[x_train_scaled, y_train]\n",
    "valid_data = np.c_[x_valid_scaled, y_valid]\n",
    "test_data = np.c_[x_test_scaled, y_test]\n",
    "\n",
    "header_cols = housing.feature_names + [\"MidianHouseValue\"]\n",
    "header_str = \",\".join(header_cols)\n",
    "\n",
    "train_filenames = save_to_csv(output_dir, train_data, \"train\", header_str, n_parts=20)\n",
    "valid_filenames = save_to_csv(output_dir, valid_data, \"valid\", header_str, n_parts=20)\n",
    "test_filenames = save_to_csv(output_dir, test_data, \"test\", header_str, n_parts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_filenames:\n",
      "['generate_csv\\\\train_00.csv',\n",
      " 'generate_csv\\\\train_01.csv',\n",
      " 'generate_csv\\\\train_02.csv',\n",
      " 'generate_csv\\\\train_03.csv',\n",
      " 'generate_csv\\\\train_04.csv',\n",
      " 'generate_csv\\\\train_05.csv',\n",
      " 'generate_csv\\\\train_06.csv',\n",
      " 'generate_csv\\\\train_07.csv',\n",
      " 'generate_csv\\\\train_08.csv',\n",
      " 'generate_csv\\\\train_09.csv',\n",
      " 'generate_csv\\\\train_10.csv',\n",
      " 'generate_csv\\\\train_11.csv',\n",
      " 'generate_csv\\\\train_12.csv',\n",
      " 'generate_csv\\\\train_13.csv',\n",
      " 'generate_csv\\\\train_14.csv',\n",
      " 'generate_csv\\\\train_15.csv',\n",
      " 'generate_csv\\\\train_16.csv',\n",
      " 'generate_csv\\\\train_17.csv',\n",
      " 'generate_csv\\\\train_18.csv',\n",
      " 'generate_csv\\\\train_19.csv']\n",
      "valid_filenames:\n",
      "['generate_csv\\\\valid_00.csv',\n",
      " 'generate_csv\\\\valid_01.csv',\n",
      " 'generate_csv\\\\valid_02.csv',\n",
      " 'generate_csv\\\\valid_03.csv',\n",
      " 'generate_csv\\\\valid_04.csv',\n",
      " 'generate_csv\\\\valid_05.csv',\n",
      " 'generate_csv\\\\valid_06.csv',\n",
      " 'generate_csv\\\\valid_07.csv',\n",
      " 'generate_csv\\\\valid_08.csv',\n",
      " 'generate_csv\\\\valid_09.csv',\n",
      " 'generate_csv\\\\valid_10.csv',\n",
      " 'generate_csv\\\\valid_11.csv',\n",
      " 'generate_csv\\\\valid_12.csv',\n",
      " 'generate_csv\\\\valid_13.csv',\n",
      " 'generate_csv\\\\valid_14.csv',\n",
      " 'generate_csv\\\\valid_15.csv',\n",
      " 'generate_csv\\\\valid_16.csv',\n",
      " 'generate_csv\\\\valid_17.csv',\n",
      " 'generate_csv\\\\valid_18.csv',\n",
      " 'generate_csv\\\\valid_19.csv']\n",
      "test_filenames:\n",
      "['generate_csv\\\\test_00.csv',\n",
      " 'generate_csv\\\\test_01.csv',\n",
      " 'generate_csv\\\\test_02.csv',\n",
      " 'generate_csv\\\\test_03.csv',\n",
      " 'generate_csv\\\\test_04.csv',\n",
      " 'generate_csv\\\\test_05.csv',\n",
      " 'generate_csv\\\\test_06.csv',\n",
      " 'generate_csv\\\\test_07.csv',\n",
      " 'generate_csv\\\\test_08.csv',\n",
      " 'generate_csv\\\\test_09.csv']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "print(\"train_filenames:\")\n",
    "pprint.pprint(train_filenames)\n",
    "print(\"valid_filenames:\")\n",
    "pprint.pprint(valid_filenames)\n",
    "print(\"test_filenames:\")\n",
    "pprint.pprint(test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'generate_csv\\\\train_03.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_13.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_10.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_15.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_05.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_12.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_01.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_04.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_17.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_06.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_00.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_02.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_16.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_14.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_11.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_07.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_09.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_19.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_08.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_18.csv', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# 1. filename -> dataset\n",
    "# 2. read file -> dataset -> datasets -> merge\n",
    "# parse csv\n",
    "\n",
    "filename_dataset = tf.data.Dataset.list_files(train_filenames)\n",
    "for filename in filename_dataset:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'-1.1199749330438333,-1.329843308393715,0.1419004518620726,0.4658136987980791,-0.10301777467500105,-0.10744184416176107,-0.7950524078397521,1.5304716763409,0.66'\n",
      "b'-1.1199749330438333,-1.329843308393715,0.1419004518620726,0.4658136987980791,-0.10301777467500105,-0.10744184416176107,-0.7950524078397521,1.5304716763409,0.66'\n",
      "b'-1.1199749330438333,-1.329843308393715,0.1419004518620726,0.4658136987980791,-0.10301777467500105,-0.10744184416176107,-0.7950524078397521,1.5304716763409,0.66'\n",
      "b'-1.1199749330438333,-1.329843308393715,0.1419004518620726,0.4658136987980791,-0.10301777467500105,-0.10744184416176107,-0.7950524078397521,1.5304716763409,0.66'\n",
      "b'-1.1199749330438333,-1.329843308393715,0.1419004518620726,0.4658136987980791,-0.10301777467500105,-0.10744184416176107,-0.7950524078397521,1.5304716763409,0.66'\n",
      "b'-0.9490938885377456,0.6726626072973063,0.28370554761513944,0.10655529643465292,-0.6546477749692311,-0.0623949278698749,0.21273656121863005,0.0024704978154519064,0.607'\n",
      "b'-0.9490938885377456,0.6726626072973063,0.28370554761513944,0.10655529643465292,-0.6546477749692311,-0.0623949278698749,0.21273656121863005,0.0024704978154519064,0.607'\n",
      "b'-0.9490938885377456,0.6726626072973063,0.28370554761513944,0.10655529643465292,-0.6546477749692311,-0.0623949278698749,0.21273656121863005,0.0024704978154519064,0.607'\n",
      "b'-0.9490938885377456,0.6726626072973063,0.28370554761513944,0.10655529643465292,-0.6546477749692311,-0.0623949278698749,0.21273656121863005,0.0024704978154519064,0.607'\n",
      "b'-0.9490938885377456,0.6726626072973063,0.28370554761513944,0.10655529643465292,-0.6546477749692311,-0.0623949278698749,0.21273656121863005,0.0024704978154519064,0.607'\n",
      "b'3.8743126570888804,-0.8492418886278699,1.2254810098923188,-0.023587924660354292,0.10202890306594632,0.03335714649304235,-1.2289615472954436,1.1709419872760878,5.00001'\n",
      "b'3.8743126570888804,-0.8492418886278699,1.2254810098923188,-0.023587924660354292,0.10202890306594632,0.03335714649304235,-1.2289615472954436,1.1709419872760878,5.00001'\n",
      "b'3.8743126570888804,-0.8492418886278699,1.2254810098923188,-0.023587924660354292,0.10202890306594632,0.03335714649304235,-1.2289615472954436,1.1709419872760878,5.00001'\n",
      "b'3.8743126570888804,-0.8492418886278699,1.2254810098923188,-0.023587924660354292,0.10202890306594632,0.03335714649304235,-1.2289615472954436,1.1709419872760878,5.00001'\n",
      "b'3.8743126570888804,-0.8492418886278699,1.2254810098923188,-0.023587924660354292,0.10202890306594632,0.03335714649304235,-1.2289615472954436,1.1709419872760878,5.00001'\n"
     ]
    }
   ],
   "source": [
    "n_readers = 5\n",
    "dataset = filename_dataset.interleave(\n",
    "    lambda fliename: tf.data.TextLineDataset(filename).skip(1),\n",
    "    cycle_length=n_readers\n",
    ")\n",
    "for line in dataset.take(15):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=4>, <tf.Tensor: shape=(), dtype=int32, numpy=5>]\n"
     ]
    }
   ],
   "source": [
    "# tf.io.decode_csv(str, record_defaults)\n",
    "\n",
    "sample_str = '1,2,3,4,5'\n",
    "record_defaults = [tf.constant(0, dtype=tf.int32)] * 5\n",
    "parse_fields = tf.io.decode_csv(sample_str, record_defaults)\n",
    "print(parse_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=float32, numpy=3.0>, <tf.Tensor: shape=(), dtype=string, numpy=b'4'>, <tf.Tensor: shape=(), dtype=float32, numpy=5.0>]\n"
     ]
    }
   ],
   "source": [
    "# tf.io.decode_csv(str, record_defaults)\n",
    "\n",
    "sample_str = '1,2,3,4,5'\n",
    "record_defaults = [\n",
    "    tf.constant(0, dtype=tf.int32),\n",
    "    0,\n",
    "    np.nan,\n",
    "    \"hello\",\n",
    "    tf.constant([])]\n",
    "parse_fields = tf.io.decode_csv(sample_str, record_defaults)\n",
    "print(parse_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field 4 is required but missing in record 0! [Op:DecodeCSV]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    parse_fields = tf.io.decode_csv(',,,,', record_defaults)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expect 5 fields but have 7 in record 0 [Op:DecodeCSV]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    parse_fields = tf.io.decode_csv('1,2,3,4,5,6,7', record_defaults)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([ 3.8743126 , -0.8492419 ,  1.225481  , -0.02358793,  0.10202891,\n",
       "         0.03335715, -1.2289616 ,  1.170942  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([5.00001], dtype=float32)>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_csv_line(line, n_fields=9):\n",
    "    defs = [tf.constant(np.nan)] * n_fields\n",
    "    parse_fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(parse_fields[0:-1])\n",
    "    y = tf.stack(parse_fields[-1:])\n",
    "    return x,y\n",
    "\n",
    "parse_csv_line(b'3.8743126570888804,-0.8492418886278699,1.2254810098923188,-0.023587924660354292,0.10202890306594632,0.03335714649304235,-1.2289615472954436,1.1709419872760878,5.00001',\n",
    "              n_fields=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function csv_reader_dataset.<locals>.<lambda> at 0x0000022A3F9561F0> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "        lambda filename: tf.data.TextLineDataset(filename).skip(1), cycle_length=n_readers\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function csv_reader_dataset.<locals>.<lambda> at 0x0000022A3F9561F0> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "        lambda filename: tf.data.TextLineDataset(filename).skip(1), cycle_length=n_readers\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "x:\n",
      "<tf.Tensor: shape=(3, 8), dtype=float32, numpy=\n",
      "array([[-8.2195884e-01,  1.8741661e+00,  1.8212350e-01, -3.1700194e-02,\n",
      "        -6.0111791e-01, -1.4337493e-01,  1.0852206e+00, -8.6139947e-01],\n",
      "       [ 1.5782312e-01,  4.3236190e-01,  3.3799481e-01, -1.5880305e-02,\n",
      "        -3.7338907e-01, -5.3052455e-02,  8.0061346e-01, -1.2359096e+00],\n",
      "       [ 4.9710345e-02, -8.4924191e-01, -6.2146995e-02,  1.7878747e-01,\n",
      "        -8.0253541e-01,  5.0660671e-04,  6.4664572e-01, -1.1060793e+00]],\n",
      "      dtype=float32)>\n",
      "y:\n",
      "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
      "array([[1.054],\n",
      "       [3.169],\n",
      "       [2.286]], dtype=float32)>\n",
      "x:\n",
      "<tf.Tensor: shape=(3, 8), dtype=float32, numpy=\n",
      "array([[-0.32652634,  0.4323619 , -0.09345459, -0.08402992,  0.8460036 ,\n",
      "        -0.02663165, -0.56176794,  0.1422876 ],\n",
      "       [-0.097193  , -1.2497431 ,  0.36232963,  0.02690608,  1.0338118 ,\n",
      "         0.04588159,  1.3418335 , -1.635387  ],\n",
      "       [-0.46794146, -0.92934215,  0.11909926, -0.06047011,  0.30344644,\n",
      "        -0.02185189,  1.8737221 , -1.0411643 ]], dtype=float32)>\n",
      "y:\n",
      "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
      "array([[2.431],\n",
      "       [1.832],\n",
      "       [1.012]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# 1. filename -> dataset\n",
    "# 2. read file -> dataset -> datasets -> merge\n",
    "# parse csv\n",
    "\n",
    "def csv_reader_dataset(filenames, n_readers=5, batch_size=32, n_parse_threads=5, shuffle_buffer_size=10000):\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filename: tf.data.TextLineDataset(filename).skip(1), cycle_length=n_readers\n",
    "    )\n",
    "    dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(parse_csv_line, num_parallel_calls = n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "train_set = csv_reader_dataset(train_filenames, batch_size=3)\n",
    "for x_batch, y_batch in train_set.take(2):\n",
    "    print(\"x:\")\n",
    "    pprint.pprint(x_batch)\n",
    "    print(\"y:\")\n",
    "    pprint.pprint(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function csv_reader_dataset.<locals>.<lambda> at 0x0000022A413474C0> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "        lambda filename: tf.data.TextLineDataset(filename).skip(1), cycle_length=n_readers\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function csv_reader_dataset.<locals>.<lambda> at 0x0000022A413474C0> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "        lambda filename: tf.data.TextLineDataset(filename).skip(1), cycle_length=n_readers\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function csv_reader_dataset.<locals>.<lambda> at 0x0000022A41347940> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "        lambda filename: tf.data.TextLineDataset(filename).skip(1), cycle_length=n_readers\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function csv_reader_dataset.<locals>.<lambda> at 0x0000022A41347940> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "        lambda filename: tf.data.TextLineDataset(filename).skip(1), cycle_length=n_readers\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function csv_reader_dataset.<locals>.<lambda> at 0x0000022A3FD57790> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "        lambda filename: tf.data.TextLineDataset(filename).skip(1), cycle_length=n_readers\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function csv_reader_dataset.<locals>.<lambda> at 0x0000022A3FD57790> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "        lambda filename: tf.data.TextLineDataset(filename).skip(1), cycle_length=n_readers\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_set = csv_reader_dataset(train_filenames, batch_size=batch_size)\n",
    "valid_set = csv_reader_dataset(valid_filenames, batch_size=batch_size)\n",
    "test_set = csv_reader_dataset(test_filenames, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "348/348 [==============================] - 0s 742us/step - loss: 2.5510 - val_loss: 1.2734\n",
      "Epoch 2/100\n",
      "348/348 [==============================] - 0s 771us/step - loss: 0.8922 - val_loss: 0.7987\n",
      "Epoch 3/100\n",
      "348/348 [==============================] - 0s 547us/step - loss: 0.6943 - val_loss: 0.7106\n",
      "Epoch 4/100\n",
      "348/348 [==============================] - 0s 519us/step - loss: 0.6368 - val_loss: 0.6791\n",
      "Epoch 5/100\n",
      "348/348 [==============================] - 0s 518us/step - loss: 0.6345 - val_loss: 0.6569\n",
      "Epoch 6/100\n",
      "348/348 [==============================] - 0s 508us/step - loss: 0.5752 - val_loss: 0.6316\n",
      "Epoch 7/100\n",
      "348/348 [==============================] - 0s 504us/step - loss: 0.5812 - val_loss: 0.6055\n",
      "Epoch 8/100\n",
      "348/348 [==============================] - 0s 510us/step - loss: 0.5481 - val_loss: 0.5886\n",
      "Epoch 9/100\n",
      "348/348 [==============================] - 0s 519us/step - loss: 0.5341 - val_loss: 0.5747\n",
      "Epoch 10/100\n",
      "348/348 [==============================] - 0s 513us/step - loss: 0.5279 - val_loss: 0.5615\n",
      "Epoch 11/100\n",
      "348/348 [==============================] - 0s 509us/step - loss: 0.5245 - val_loss: 0.5469\n",
      "Epoch 12/100\n",
      "348/348 [==============================] - 0s 507us/step - loss: 0.4959 - val_loss: 0.5334\n",
      "Epoch 13/100\n",
      "348/348 [==============================] - 0s 513us/step - loss: 0.5027 - val_loss: 0.5302\n",
      "Epoch 14/100\n",
      "348/348 [==============================] - 0s 524us/step - loss: 0.4851 - val_loss: 0.5154\n",
      "Epoch 15/100\n",
      "348/348 [==============================] - 0s 536us/step - loss: 0.4876 - val_loss: 0.5139\n",
      "Epoch 16/100\n",
      "348/348 [==============================] - 0s 539us/step - loss: 0.4730 - val_loss: 0.5044\n",
      "Epoch 17/100\n",
      "348/348 [==============================] - 0s 519us/step - loss: 0.4758 - val_loss: 0.5002\n",
      "Epoch 18/100\n",
      "348/348 [==============================] - 0s 516us/step - loss: 0.4704 - val_loss: 0.4952\n",
      "Epoch 19/100\n",
      "348/348 [==============================] - 0s 527us/step - loss: 0.4579 - val_loss: 0.4883\n",
      "Epoch 20/100\n",
      "348/348 [==============================] - 0s 508us/step - loss: 0.4604 - val_loss: 0.4846\n",
      "Epoch 21/100\n",
      "348/348 [==============================] - 0s 510us/step - loss: 0.4578 - val_loss: 0.4826\n",
      "Epoch 22/100\n",
      "348/348 [==============================] - 0s 509us/step - loss: 0.4544 - val_loss: 0.4768\n",
      "Epoch 23/100\n",
      "348/348 [==============================] - 0s 515us/step - loss: 0.4466 - val_loss: 0.4733\n",
      "Epoch 24/100\n",
      "348/348 [==============================] - 0s 510us/step - loss: 0.4494 - val_loss: 0.4689\n",
      "Epoch 25/100\n",
      "348/348 [==============================] - 0s 510us/step - loss: 0.4437 - val_loss: 0.4684\n",
      "Epoch 26/100\n",
      "348/348 [==============================] - 0s 516us/step - loss: 0.4383 - val_loss: 0.4613\n",
      "Epoch 27/100\n",
      "348/348 [==============================] - 0s 524us/step - loss: 0.4404 - val_loss: 0.4618\n",
      "Epoch 28/100\n",
      "348/348 [==============================] - 0s 507us/step - loss: 0.4319 - val_loss: 0.4573\n",
      "Epoch 29/100\n",
      "348/348 [==============================] - 0s 510us/step - loss: 0.4370 - val_loss: 0.4536\n",
      "Epoch 30/100\n",
      "348/348 [==============================] - 0s 510us/step - loss: 0.4315 - val_loss: 0.4510\n",
      "Epoch 31/100\n",
      "348/348 [==============================] - 0s 520us/step - loss: 0.4317 - val_loss: 0.4531\n",
      "Epoch 32/100\n",
      "348/348 [==============================] - 0s 515us/step - loss: 0.4312 - val_loss: 0.4521\n",
      "Epoch 33/100\n",
      "348/348 [==============================] - 0s 516us/step - loss: 0.4172 - val_loss: 0.4476\n",
      "Epoch 34/100\n",
      "348/348 [==============================] - 0s 519us/step - loss: 0.4249 - val_loss: 0.4441\n",
      "Epoch 35/100\n",
      "348/348 [==============================] - 0s 522us/step - loss: 0.4378 - val_loss: 0.4425\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(0.001))\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta=1e-2)]\n",
    "\n",
    "history = model.fit(train_set,\n",
    "                    validation_data=valid_set,\n",
    "                    steps_per_epoch = 11160 // batch_size,\n",
    "                    validation_steps = 3837 // batch_size,\n",
    "                    epochs=100,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 372us/step - loss: 0.4390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.43904489278793335"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set, steps=5160//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_gpu",
   "language": "python",
   "name": "tf2_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
