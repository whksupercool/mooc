{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=8, micro=3, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.2\n",
      "numpy 1.18.5\n",
      "pandas 1.0.5\n",
      "sklearn 0.23.1\n",
      "tensorflow.compat.v1 2.3.1\n",
      "tensorflow.keras 2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28) (5000,)\n",
      "(55000, 28, 28) (55000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
    "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
    "\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(x_train), np.min(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "归一化 x = (x - u) / std  u:均值，std:方差\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# x_train: [None, 28, 28] -> [None, 784]\n",
    "x_train_scaled = scaler.fit_transform(\n",
    "    x_train.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
    "x_valid_scaled = scaler.transform(\n",
    "    x_valid.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
    "x_test_scaled = scaler.transform(\n",
    "    x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
    "\n",
    "y_train = np.asarray(y_train, dtype = np.int64)\n",
    "y_valid = np.asarray(y_valid, dtype = np.int64)\n",
    "y_test = np.asarray(y_test, dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0231433 -0.8105136\n"
     ]
    }
   ],
   "source": [
    "print(np.max(x_train_scaled), np.min(x_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(images, labels, epochs, batch_size, shuffle = True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 784)\n",
      "(20,)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "All components must have the same size in the 0th dimension\n\t [[node TensorSliceDataset_9 (defined at <ipython-input-19-493585fc29fe>:2) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node TensorSliceDataset_9:\n Placeholder_18 (defined at <ipython-input-21-9080be0392fc>:4)\t\n Placeholder_19 (defined at <ipython-input-21-9080be0392fc>:5)\n\nOriginal stack trace for 'TensorSliceDataset_9':\n  File \"D:\\software\\anaconda\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"D:\\software\\anaconda\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\software\\anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"D:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\software\\anaconda\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"D:\\software\\anaconda\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"D:\\software\\anaconda\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2866, in run_cell\n    result = self._run_cell(\n  File \"D:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3071, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"D:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"D:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-9080be0392fc>\", line 7, in <module>\n    dataset = make_dataset(images_placeholder, labels_placeholder,\n  File \"<ipython-input-19-493585fc29fe>\", line 2, in make_dataset\n    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 2421, in from_tensor_slices\n    return DatasetV1Adapter(DatasetV2.from_tensor_slices(tensors))\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 682, in from_tensor_slices\n    return TensorSliceDataset(tensors)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 3013, in __init__\n    variant_tensor = gen_dataset_ops.tensor_slice_dataset(\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 6698, in tensor_slice_dataset\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 742, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3477, in _create_op_internal\n    ret = Operation(\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1949, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mD:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1350\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[1;32mD:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1440\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1441\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: All components must have the same size in the 0th dimension\n\t [[{{node TensorSliceDataset_9}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-9080be0392fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     sess.run(dataset_iter.initializer,\n\u001b[0m\u001b[0;32m     23\u001b[0m              feed_dict = {\n\u001b[0;32m     24\u001b[0m                  \u001b[0mimages_placeholder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_valid_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    958\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    959\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1181\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1182\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1358\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1359\u001b[0m                            run_metadata)\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: All components must have the same size in the 0th dimension\n\t [[node TensorSliceDataset_9 (defined at <ipython-input-19-493585fc29fe>:2) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node TensorSliceDataset_9:\n Placeholder_18 (defined at <ipython-input-21-9080be0392fc>:4)\t\n Placeholder_19 (defined at <ipython-input-21-9080be0392fc>:5)\n\nOriginal stack trace for 'TensorSliceDataset_9':\n  File \"D:\\software\\anaconda\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"D:\\software\\anaconda\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\software\\anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"D:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\software\\anaconda\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"D:\\software\\anaconda\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"D:\\software\\anaconda\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2866, in run_cell\n    result = self._run_cell(\n  File \"D:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3071, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"D:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"D:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-9080be0392fc>\", line 7, in <module>\n    dataset = make_dataset(images_placeholder, labels_placeholder,\n  File \"<ipython-input-19-493585fc29fe>\", line 2, in make_dataset\n    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 2421, in from_tensor_slices\n    return DatasetV1Adapter(DatasetV2.from_tensor_slices(tensors))\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 682, in from_tensor_slices\n    return TensorSliceDataset(tensors)\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 3013, in __init__\n    variant_tensor = gen_dataset_ops.tensor_slice_dataset(\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 6698, in tensor_slice_dataset\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 742, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3477, in _create_op_internal\n    ret = Operation(\n  File \"D:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1949, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "epochs = 10\n",
    "\n",
    "images_placeholder = tf.placeholder(tf.float32, [None, 28 * 28])\n",
    "labels_placeholder = tf.placeholder(tf.int64, (None,))\n",
    "\n",
    "dataset = make_dataset(images_placeholder, labels_placeholder,\n",
    "                       epochs = epochs,\n",
    "                       batch_size = batch_size)\n",
    "\n",
    "dataset_iter = dataset.make_initializable_iterator()\n",
    "x, y = dataset_iter.get_next()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(dataset_iter.initializer,\n",
    "             feed_dict = {\n",
    "                 images_placeholder: x_train_scaled,\n",
    "                 labels_placeholder: y_train\n",
    "             })\n",
    "    x_val, y_val = sess.run([x, y])\n",
    "    print(x_val.shape)\n",
    "    print(y_val.shape)\n",
    "    sess.run(dataset_iter.initializer,\n",
    "             feed_dict = {\n",
    "                 images_placeholder: x_valid_scaled,\n",
    "                 labels_placeholder: y_valid,\n",
    "             })\n",
    "    x_val, y_val = sess.run([x, y])\n",
    "    print(x_val.shape)\n",
    "    print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = [100, 100]\n",
    "class_num = 10\n",
    "\n",
    "# x = tf.placeholder(tf.float32, [None, 28 * 28])\n",
    "# y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "input_for_next_layer = x\n",
    "for hidden_unit in hidden_units:\n",
    "    input_for_next_layer = tf.layers.dense(input_for_next_layer, hidden_unit, activation=tf.nn.relu)\n",
    "\n",
    "logits = tf.layers.dense(input_for_next_layer, class_num)\n",
    "\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits)\n",
    "\n",
    "prediction = tf.argmax(logits, 1)\n",
    "correct_prediction = tf.equal(prediction, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "train_steps_per_epoch = x_train.shape[0] // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        for step in range(train_steps_per_epoch):\n",
    "            loss_val, accuracy_val, _ = sess.run(\n",
    "                [loss, accuracy, train_op])\n",
    "            print('\\r[Train] epoch: %02d, step: %d, loss: %3.5f, accuracy: %2.2f' % (\n",
    "                epoch, step, loss_val, accuracy_val), end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_gpu",
   "language": "python",
   "name": "tf2_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
